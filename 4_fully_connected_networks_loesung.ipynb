{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81347816",
   "metadata": {},
   "source": [
    "# Fully Connected Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335204d6",
   "metadata": {},
   "source": [
    "Wir beschäftigen uns in diesen Notebook mit Neuronalen Netzen, die fully connected Layer haben. Zunächst wollen wir eine einfache Funktion mit einer Variablen fitten und anschließend klassifizieren wir Bilder von Ziffern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46ef6f",
   "metadata": {},
   "source": [
    "## Eindimensionale Funktion fitten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893564db",
   "metadata": {},
   "source": [
    "### Aufgabe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493573a",
   "metadata": {},
   "source": [
    "Lade zuerst die Datensätze `1d_dataset_train.pt` und `1d_dataset_test.pt` und stelle sie grafisch dar. Die Funktion [`torch.load`](https://pytorch.org/docs/stable/generated/torch.load.html) könnte dabei hilfreich sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "data_train = torch.load('data/1d_dataset_train.pt')\n",
    "x_train = data_train['x']\n",
    "y_train = data_train['y']\n",
    "\n",
    "data_test = torch.load('data/1d_dataset_test.pt')\n",
    "x_test = data_test['x']\n",
    "y_test = data_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, '.b', markersize=0.1)\n",
    "plt.plot(x_test, y_test, '.r', markersize=0.1)\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc589126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03478bdf",
   "metadata": {},
   "source": [
    "### Aufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524368a",
   "metadata": {},
   "source": [
    "Nun wollen wir uns ein neuronales Netz bauen. In `torch.nn` sind viele Layer implementiert, die wir nutzen wollen. Hier benötigen wir das fully connected Layer [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) sowie die Aktivierungsfunktion [`torch.nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html). Die beiden genannten Funktionen sind nicht die Layer selbst, sondern sie erzeugen ein Layer, was in folgenden Beispiel veranschaulicht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc84892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiermit erzeugen wir das Layer.\n",
    "# Es verlangt 2 Feature als Input und gibt 3 Feature zurück\n",
    "linear_layer = torch.nn.Linear(in_features=2, out_features=3) \n",
    "\n",
    "# Um die Anwendung des Layers zu testen, erzeugen wir zunächst einen Beispieldatenpunkt.\n",
    "x = torch.randn(1, 2) # Batch size: 1, Anzahl der Feature: 2\n",
    "print('x: ', x)\n",
    "\n",
    "# Nun können wir den Datenpunkt mit dem Layer verarbeiten und das Ergebnis anzeigen lassen.\n",
    "out = linear_layer(x)\n",
    "print('output: ', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktivierungsfunktion\n",
    "act_fn = torch.nn.ReLU()\n",
    "\n",
    "print('x: ', x)\n",
    "\n",
    "out_lin = linear_layer(x)\n",
    "print('output linear layer: ', out_lin)\n",
    "\n",
    "out_act = act_fn(out_lin)\n",
    "print('output linear layer: ', out_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11979417",
   "metadata": {},
   "source": [
    "Einzelne Layer können mithilfe des Befehls [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) zu einem Netzwerk zusammen gefügt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e80653",
   "metadata": {},
   "source": [
    "Baue ein neuronales Netz, was aus einem Input Layer, einem Output Layer und zwei hidden Layer mit jeweils 16 hidden Units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0234c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(16, 16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(16, 16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(16, 1)    \n",
    ")\n",
    "\n",
    "# Teste dein Netzwerk\n",
    "x = torch.randn(2, 1)\n",
    "print('Testdatenpunkt x: ', x)\n",
    "out = net(x)\n",
    "print('Output: ', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ac703",
   "metadata": {},
   "source": [
    "### Aufgabe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0b766",
   "metadata": {},
   "source": [
    "Um das Netzwerk trainieren zu können, benötigen wir eine Loss-Funktion und einen `Optimizer`. Als Loss wollen wir den Mean Squared Error (MSE) verwenden, der in PyTorch [`torch.nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html) heißt.\n",
    "\n",
    "Ein sehr populärer `Optimizer`, den wir nutzen wollen, ist [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122a634",
   "metadata": {},
   "source": [
    "Erzeuge die Loss-Funktion und den `Optimizer` für dein Netzwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3dd22",
   "metadata": {},
   "source": [
    "### Aufgabe 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a93288",
   "metadata": {},
   "source": [
    "Jetzt sind wir bereit für das Training. In jedem Trainingsschritt müssen wir zufällig ein Mini-Batch aus dem Datensatz ziehen, wobei die Funktion [`torch.randint`](https://pytorch.org/docs/stable/generated/torch.randint.html) hilfreich sein könnte. Dieses Mini-Batch wird in das Netzwerk gegeben und aus dem vorhergesagten und den tatsächlichen Werten für `y` wird der Loss ermittelt. Der Backpropagation-Algorithmus wird via `loss.backward()` angewandt und anschließend werden die Parameter des Netzwerks geupdated mit `optimizer.step()`. Nach jedem Schritt müssen die Gradienten mittels `optimizer.zero_grad()` zurückgesetzt werden.\n",
    "\n",
    "Dieser Trainingsschritt wird mit einer `for`-Schleife mehrfach wiederholt, bis das Netzwerk trainiert ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a47ef",
   "metadata": {},
   "source": [
    "Implementiere den Trainingsalgorithmus und trainiere dein Netzwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "for it in tqdm(range(max_iter)):\n",
    "    # Erzeuge Mini-Batch\n",
    "    batch_ind = torch.randint(len(x_train), (16,))\n",
    "    x_batch = x_train[batch_ind, :]\n",
    "    y_batch = y_train[batch_ind, :]\n",
    "    \n",
    "    # Vorhersage des Netzwerks\n",
    "    y_pred = net(x_batch)\n",
    "    \n",
    "    # Loss berechnen\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528582d7",
   "metadata": {},
   "source": [
    "### Aufgabe 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3b9d2",
   "metadata": {},
   "source": [
    "Berechne die Vorhersagen des Netzwerkes und bestimme den Loss auf dem Testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55819fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_test = net(x_test)\n",
    "    print(loss_fn(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c8b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951b4ad8",
   "metadata": {},
   "source": [
    "### Aufgabe 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dacb1",
   "metadata": {},
   "source": [
    "Erweitere deinen Trainingsalgorithmus, sodass schon während des Trainings die Performance des Netzes in regelmäßigen Abständen bestimmt wird und der Loss gespeichert wird, sodass du ihn nach dem Training plotten kannst.\n",
    "\n",
    "Passe außerdem deine Netzwerkarchitektur und die Trainingsparameter an, sodass du bessere Ergebnisse bekommst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d520b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 1)    \n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "\n",
    "max_iter = 2000\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "for it in tqdm(range(max_iter)):\n",
    "    # Erzeuge Mini-Batch\n",
    "    batch_ind = torch.randint(len(x_train), (64,))\n",
    "    x_batch = x_train[batch_ind, :]\n",
    "    y_batch = y_train[batch_ind, :]\n",
    "    \n",
    "    # Vorhersage des Netzwerks\n",
    "    y_pred = net(x_batch)\n",
    "    \n",
    "    # Loss berechnen\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Speichere Loss\n",
    "    loss_hist.append(loss.item())\n",
    "    \n",
    "    # Evaluierung\n",
    "    if it % 100 == 0:\n",
    "        # Loss auf Testdaten berechnen\n",
    "        with torch.no_grad():\n",
    "            y_pred_test = net(x_test)\n",
    "            print(loss_fn(y_pred_test, y_test))\n",
    "\n",
    "        # Ergebnisse grafisch darstellen\n",
    "        plt.plot(x_test, y_test, '.')\n",
    "        plt.plot(x_test, y_pred_test, '.')\n",
    "        plt.legend(['Testdaten', 'Vorhersage NN'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b35fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss während des Trainings plotten\n",
    "plt.plot(loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss auf Testdaten berechnen\n",
    "with torch.no_grad():\n",
    "    y_pred_test = net(x_test)\n",
    "    print(loss_fn(y_pred_test, y_test))\n",
    "\n",
    "# Ergebnisse grafisch darstellen\n",
    "plt.plot(x_test, y_test, '.')\n",
    "plt.plot(x_test, y_pred_test, '.')\n",
    "plt.legend(['Testdaten', 'Vorhersage NN'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22233b62",
   "metadata": {},
   "source": [
    "## Ziffern klassifizieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed6611",
   "metadata": {},
   "source": [
    "### Aufgabe 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5172aad",
   "metadata": {},
   "source": [
    "Als nächstes widmen wir uns der Klassifikation von Ziffern. Wir tuen dies anhand des MNIST-Datensatzes, den man sich über die Funktion [`torchvision.datasets.MNIST`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) herunterladen kann. Außerdem kannst du mit der Funktion direkt Transformationen auf dem Datensatz ausführen. Wir wollen die Bilder direkt mit [`torchvision.transforms.ToTensor`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor) zu Tensoren konvertieren.\n",
    "\n",
    "Lade das Trainings- und Testset herunter und visualisiere einige der Ziffern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST('data/', train=True, \n",
    "                                         transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "mnist_test = torchvision.datasets.MNIST('data/', train=False, \n",
    "                                         transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9911f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plt.imshow(torch.reshape(mnist_train[i][0], (28, 28)))\n",
    "    plt.show()\n",
    "\n",
    "    print(mnist_train[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79326c77",
   "metadata": {},
   "source": [
    "### Aufgabe 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a06993d",
   "metadata": {},
   "source": [
    "Beim Training des letzten Modells haben wir die Mini-Batches manuell erzeugt. Allerdings gibt es die Funktion [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), die einem diese Aufgabe abnehmen.\n",
    "\n",
    "Erzeuge einen solchen `DataLoader` für das Trainings- und Testset. Achte darauf, dass die Trainingsdaten gemischt werden müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d40484",
   "metadata": {},
   "source": [
    "### Aufgabe 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836dfc49",
   "metadata": {},
   "source": [
    "Der Aufbau der neuronalen Netzes, welches wir zur Klassifikaiton der Ziffern nehmen, ist ähnlich dem im vorherigen Problem, allerdings müssen wir einige Dinge beachten.\n",
    "\n",
    "Da es sich um Bilder handelt, müssen wir diese erst in Vektoren umwandeln. Das ist mit der Funktion [`torch.nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) möglich. Außerdem muss das Netzwerk jetzt 10 Zahlen zurück geben, aus denen die Wahrscheinlichkeiten für die jeweiligen Klassen bestimmt werden können.\n",
    "\n",
    "Implementiere ein solches Netz. Erstelle außerdem den `Optimizer` und den für Klassifikation benötigten [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e839b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 ** 2, 64), \n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.Linear(64, 64), \n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.Linear(64, 64), \n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.Linear(64, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f86930",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f28330",
   "metadata": {},
   "source": [
    "### Aufgabe 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2bd4b",
   "metadata": {},
   "source": [
    "Um das Netzwerk zu trainieren, führen wir eine `for`-Schleife über den `DataLoader` aus. Damit iterieren wir einmal durch den gesamten Datensatz, was als eine Epoche bezeichnet wird. Mit einer zweiten `for`-Schleife können wir mehrere solcher Epochen ausführen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db771cc",
   "metadata": {},
   "source": [
    "Ergänze den Trainingsalgorithmus und trainiere dein Modell. Plotte anschließen den Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1881f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "for ep in range(n_epoch):\n",
    "    for x_batch, y_batch in tqdm(train_loader):\n",
    "        # Vorhersage des Netzwerks\n",
    "        y_pred = net(x_batch)\n",
    "\n",
    "        # Loss berechnen\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Speichere Loss\n",
    "        loss_hist.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b09f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c47f1c",
   "metadata": {},
   "source": [
    "### Aufgabe 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965482e7",
   "metadata": {},
   "source": [
    "Berechne die Genauigkeit deines Netzwerkes, also wie viele Bilder richtig klassifiziert werden, auf dem Testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_correct = 0\n",
    "sum_imgs = 0\n",
    "\n",
    "for x_batch, y_batch in tqdm(test_loader):\n",
    "    # Vorhersage des Netzes ohne Gradientenberechnung\n",
    "    with torch.no_grad():\n",
    "        y_pred = # ???\n",
    "    \n",
    "    # Vorhergesagtes Label\n",
    "    y_pred = # ???\n",
    "        \n",
    "    # Anzahl der Bilder updaten\n",
    "    sum_imgs += len(x_batch)\n",
    "    \n",
    "    # Anzahl der korrekt klassifizierten Bilder\n",
    "    sum_correct += # ???\n",
    "\n",
    "# Accuracy berechnen und ausgeben\n",
    "accuracy = sum_correct / sum_imgs\n",
    "print('Accuracy auf dem Testset: ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376999e",
   "metadata": {},
   "source": [
    "### Aufgabe 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b76177",
   "metadata": {},
   "source": [
    "Wiederhole das Training und berechne die Genauigkeit diesmal nach jeder Epoche. Verbessere außerdem deine Netzwerkarchitektur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Du kannst deinen Code aus den vorherigen Aufgaben nutzen und anpassen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
